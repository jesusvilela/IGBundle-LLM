# ManifoldGL / IGBundle ‚Äî Geometry-aware LLM Adapters

I'm excited to share a research preview of **ManifoldGL**, a framework for parameter-efficient LLM adaptation that treats meaning as a fiber bundle over a hyperbolic base manifold.

**The approach achieved +131% improvement on abstract reasoning (ARC-AGI) over baseline**, demonstrating that geometric inductive biases can fundamentally enhance how models learn hierarchical concepts.

**Key ideas:**
‚Ä¢ Hyperbolic geometry (Œ∫ = -1) as an inductive bias for hierarchical semantics
‚Ä¢ Sheaf-consistency loss to enforce local meaning alignment across context patches
‚Ä¢ Lightweight adapter architecture (0.9% params) that projects into a Riemannian manifold
‚Ä¢ Natural gradient optimization on the Fisher information geometry

**Results:**
‚Ä¢ 28.7% accuracy on ARC-AGI vs 12.4% baseline (Qwen2.5-7B) ‚Äî +131.5% relative improvement
‚Ä¢ 94.2% Manifold Faithfulness Rate (representations respect geometric constraints)
‚Ä¢ Converged to target hyperbolic curvature (Œ∫ = -0.98) with only 4% inference overhead

**What's in the repo:**
‚Ä¢ Complete mathematical framework with 30-page thesis
‚Ä¢ Reproducible evaluation pipeline with statistical rigor (13 ablation studies)
‚Ä¢ Verification agents to check geometric integrity
‚Ä¢ Interactive topology visualizations

I'm opening the project to feedback and collaborators‚Äîespecially folks interested in differential geometry, interpretability, or geometric deep learning.

**GitHub:** [repository link]

What geometric structures do you think are hiding in your models' latent spaces? üåê

---

**Hashtags:** #MachineLearning #GeometricDeepLearning #LLM #AbstractReasoning #DifferentialGeometry #AIResearch #OpenSource
