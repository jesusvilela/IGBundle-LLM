# ManifoldGL: Information-Geometric Bundle Adapters for LLMs

<div align="center">

**ğŸŒŒ The Geometry of Reasoning: Non-Euclidean Latent Spaces for Abstract Intelligence**

[![License: All Rights Reserved](https://img.shields.io/badge/License-All_Rights_Reserved-red.svg)](LICENSE)
![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)
![PyTorch 2.6](https://img.shields.io/badge/PyTorch-2.6-ee4c2c.svg)
![Status: Research](https://img.shields.io/badge/Status-Research_Preview-purple.svg)

---

### ğŸ“š Documentation

**[ğŸ“„ Scientific Thesis v2.1 (Enhanced)](ManifoldGL_Scientific_Thesis_v2.1_ENHANCED.md)** â€¢ **[ğŸ”¬ Peer Review Report](PEER_REVIEW_COMMITTEE_REPORT_COMPREHENSIVE.md)** â€¢ **[ğŸ“Š Ablation Framework](ablation_results/ABLATION_STUDIES.md)**

---

</div>

## ğŸ¯ Overview

**ManifoldGL** introduces a mathematically rigorous parameter-efficient fine-tuning (PEFT) framework that adapts Large Language Models through **information-geometric constraints** within a **fiber bundle architecture**. Unlike standard LoRA which operates in flat Euclidean space, ManifoldGL models semantic latent space as a **Fiber Bundle** ($\pi: E \rightarrow M$) over a **Riemannian Base Manifold** with learned hyperbolic geometry.

### Key Innovation

```mermaid
graph LR
    A[Traditional LoRA] -->|Euclidean Space| B[Flat Geometry]
    C[ManifoldGL] -->|Riemannian Manifold| D[Hyperbolic Geometry]

    B -.->|Limited| E[Hierarchical Structures]
    D ==>|Natural| E

    style C fill:#e1f5e1
    style D fill:#e1f5e1
    style E fill:#fff3cd
```

**Why Hyperbolic Geometry?** Hierarchical semantic structures (taxonomies, concept trees, entailment chains) expand exponentially with depth. Hyperbolic spaces naturally accommodate this exponential volume growth, while Euclidean spaces suffer from representation collapse.

---

## ğŸ—ï¸ Architecture

<div align="center">

```mermaid
graph TD
    A["ğŸ”¤ Base LLM<br/>(Qwen2.5-7B)"] -->|"Input Tokens"| B["ğŸ“¦ IGBundle Adapter<br/>(0.9% parameters)"]

    B -->|"1. Project"| C["â¬‡ï¸ Bottleneck<br/>H â†’ D_bot"]
    C -->|"2. Extract"| D["ğŸ“ Base Coords (M)<br/>ğŸ“Š Fiber Dists (F)"]

    D -->|"3. Compute"| E["ğŸ“ Riemannian Metric<br/>g = LÂ·L^T"]
    E -->|"4. Apply"| F["ğŸ”„ Geometric Ops<br/>(Î»-calculus inspired)"]

    F -->|"5. Aggregate"| G["ğŸŒ Riemannian Weighted<br/>Mean on Manifold"]
    G -->|"6. Project"| H["â¬†ï¸ Output<br/>(D_bot + K) â†’ H"]

    H -->|"Residual Add"| A

    subgraph "Geometric Constraints"
    I["ğŸ“‰ Curvature Loss<br/>K(u,v) â†’ -1.0"]
    J["ğŸ”— Sheaf Consistency<br/>JS(patches)"]
    K["ğŸ“¦ Bundle Structure<br/>Local Triviality"]
    end

    E -.->|"Regularize"| I
    F -.->|"Constrain"| J
    F -.->|"Preserve"| K

    style A fill:#e3f2fd
    style B fill:#c8e6c9
    style E fill:#fff9c4
    style F fill:#ffe0b2
    style G fill:#f8bbd0
```

</div>

### Mathematical Foundation

| Component | Theory | Implementation |
|:----------|:-------|:---------------|
| **Metric Tensor** | $g = L \cdot L^T$ (Cholesky) | âœ… Exact |
| **Christoffel Symbols** | $\Gamma^k_{ij} = \frac{1}{2}g^{kl}(\partial_j g_{il} + ...)$ | âš ï¸ Neural approximation |
| **Riemann Curvature** | $R^i_{jkl} = \partial_k\Gamma^i_{jl} - ...$ | âš ï¸ Finite differences |
| **Fisher Information** | $F_{ij} = \mathbb{E}[\partial_i \log p \cdot \partial_j \log p]$ | âš ï¸ Diagonal approx |
| **Natural Gradients** | $\theta \leftarrow \theta - \eta F^{-1}\nabla\mathcal{L}$ | âœ… Diagonal efficient |
| **Sheaf Consistency** | Gluing conditions | âš ï¸ Soft JS divergence |

**Legend**: âœ… Exact computation | âš ï¸ Approximation for tractability

See [Section 2.6 of the thesis](ManifoldGL_Scientific_Thesis_v2.1_ENHANCED.md#26-implementation-approximations-new-section) for detailed approximation documentation.

---

## ğŸ”¬ Experimental Framework

### Designed Validation Protocol

```mermaid
gantt
    title Experimental Validation Roadmap
    dateFormat  YYYY-MM-DD
    section Ablation Studies
    13 Systematic Ablations       :active, 2026-01-03, 30d
    Statistical Analysis          :        2026-02-02, 14d
    section Comparative Studies
    8 Baseline Comparisons        :        2026-01-03, 45d
    Hyperbolic Embeddings Compare :        2026-02-17, 21d
    section Benchmarks
    ARC-AGI Full Evaluation       :crit,   2026-01-03, 60d
    MMLU, GSM8K, HumanEval        :        2026-03-04, 45d
```

### Ablation Studies (Framework)

| Study | Research Question | Status |
|:------|:------------------|:-------|
| **no_curvature_loss** | How much does curvature regularization contribute? | ğŸŸ¡ Configured |
| **no_natural_gradients** | Impact of information-geometric optimization? | ğŸŸ¡ Configured |
| **euclidean_target** | Is hyperbolic geometry essential? | ğŸŸ¡ Configured |
| **standard_igbundle** | Total improvement from geometric corrections? | ğŸŸ¡ Configured |
| **lora_only_baseline** | Total benefit of IGBundle vs pure LoRA? | ğŸŸ¡ Configured |
| *+ 8 more studies* | Architecture, learning rates, schedules | ğŸŸ¡ Configured |

**Legend**: ğŸŸ¢ Complete | ğŸŸ¡ Framework ready | ğŸ”´ Not started

### Preliminary Results (Requires Validation)

**âš ï¸ STATUS**: Small-scale preliminary testing (n=20, 25 steps). Full validation requires nâ‰¥100, 1000+ steps.

| Experiment | Observed | Statistical Confidence | Next Steps |
|:-----------|:---------|:-----------------------|:-----------|
| Riemannian vs Euclidean | -3.4% entropy | âš ï¸ n=1 insufficient | Replicate with nâ‰¥5 |
| ARC-AGI Framework | 0% (n=20) | Framework validated | Scale to nâ‰¥100 |
| Geometric Convergence | Negative curvature trend | Qualitative observation | Quantitative analysis |

---

## ğŸ“Š Repository Structure

```
IGBundle-LLM/
â”œâ”€â”€ ğŸ“„ ManifoldGL_Scientific_Thesis_v2.1_ENHANCED.md    # Main scientific thesis
â”œâ”€â”€ ğŸ”¬ PEER_REVIEW_COMMITTEE_REPORT_COMPREHENSIVE.md    # Multi-agent peer review
â”œâ”€â”€ src/
â”‚   â””â”€â”€ igbundle/
â”‚       â”œâ”€â”€ geometry/
â”‚       â”‚   â”œâ”€â”€ riemannian.py                  # Riemannian geometry implementation
â”‚       â”‚   â”œâ”€â”€ adaptive_curvature.py          # Adaptive curvature targeting
â”‚       â”‚   â””â”€â”€ multiscale_attention.py        # Multi-scale geometric attention
â”‚       â”œâ”€â”€ modules/
â”‚       â”‚   â”œâ”€â”€ geometric_adapter.py           # Main adapter (corrected)
â”‚       â”‚   â”œâ”€â”€ adapter.py                     # Original (compatibility)
â”‚       â”‚   â”œâ”€â”€ state.py                       # Mixture state
â”‚       â”‚   â””â”€â”€ ops.py                         # Bundle operations
â”‚       â””â”€â”€ training/
â”‚           â”œâ”€â”€ geometric_training.py          # Natural gradient optimization
â”‚           â””â”€â”€ meta_geometric_optimization.py # Meta-learning
â”œâ”€â”€ ablation_results/
â”‚   â”œâ”€â”€ ABLATION_STUDIES.md                    # 13 ablation framework
â”‚   â””â”€â”€ ablation_studies_summary.json          # Configuration
â”œâ”€â”€ comparative_results/
â”‚   â””â”€â”€ COMPARATIVE_STUDIES.md                 # 8 comparative framework
â”œâ”€â”€ eval_arc.py                                # ARC-AGI evaluation with confidence intervals
â”œâ”€â”€ train.py                                   # Training script
â”œâ”€â”€ generate_thesis.py                         # PDF generation
â””â”€â”€ auxiliary_crew.py                          # Verification agents
```

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/jesusvilela/IGBundle-LLM.git
cd IGBundle-LLM

# Install dependencies
pip install -r requirements.txt

# Install package in development mode
pip install -e .
```

### Basic Usage

```python
from igbundle import GeometricAdapter
from transformers import AutoModelForCausalLM

# Load base model
model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-7B-Instruct")

# Add geometric adapter
adapter = GeometricAdapter(
    num_components=4,      # Mixture components (P)
    num_categories=16,     # Fiber categories (K)
    latent_dim=128,        # Bottleneck dimension (D)
    geometry="riemannian"  # Enable Riemannian geometry
)

# Training with natural gradients
from igbundle.training import NaturalGradientOptimizer

optimizer = NaturalGradientOptimizer(
    adapter.parameters(),
    lr=5e-5,
    use_natural_gradients=True
)

# Train with geometric constraints
trainer.train(
    lambda_curvature=0.01,    # Curvature regularization
    lambda_sheaf=0.005,       # Sheaf consistency
    lambda_bundle=0.005,      # Bundle structure
    target_curvature=-1.0     # Hyperbolic target
)
```

### Run Evaluation

```bash
# ARC-AGI evaluation with strict confidence intervals
python eval_arc.py \
    --checkpoint output/igbundle_qwen7b_riemannian/checkpoint-50 \
    --limit 100 \
    --mfr \
    --confidence-level 0.95

# Launch verification agents
python auxiliary_crew.py

# Generate thesis PDF
python generate_thesis.py  # Output: output/thesis/IGBundle_Thesis.pdf
```

---

## ğŸ“ˆ Experimental Results

### Current Status

**âš ï¸ TRANSPARENCY STATEMENT**: This is a research preview with preliminary validation. Full experimental protocol designed but requires complete execution.

#### Completed
- âœ… Mathematical framework established
- âœ… Implementation with neural approximations
- âœ… Ablation framework designed (13 studies)
- âœ… Comparative framework designed (8 studies)
- âœ… Preliminary small-scale testing (n=20)

#### In Progress
- ğŸ”„ Full ARC-AGI evaluation (target: nâ‰¥100)
- ğŸ”„ Ablation study execution (13 studies)
- ğŸ”„ Comparative study execution (8 studies)
- ğŸ”„ Extended training (1000+ steps)

#### Planned
- ğŸ“‹ Multi-benchmark evaluation (MMLU, GSM8K, HumanEval)
- ğŸ“‹ Multi-model validation (Llama, Mistral, Gemma)
- ğŸ“‹ Baseline comparisons (hyperbolic embeddings, QLoRA)
- ğŸ“‹ Independent peer review

### Preliminary Observations

| Metric | Observation | Confidence | Note |
|:-------|:------------|:-----------|:-----|
| **Geometric Convergence** | Negative curvature trend | Qualitative | Requires quantitative analysis |
| **Mixture Specialization** | -3.4% entropy (Riemannian vs Euclidean) | âš ï¸ Low (n=1) | Requires nâ‰¥5 replication |
| **Parameter Efficiency** | 0.9% additional parameters | âœ… Verified | Similar to LoRA |

**See [Section 4 of the thesis](ManifoldGL_Scientific_Thesis_v2.1_ENHANCED.md#4-experimental-validation) for detailed methodology and limitations.**

---

## ğŸ“ Scientific Contributions

### 1. Riemannian Geometric Framework
- Learned metric tensors via Cholesky parameterization
- Neural approximations to Christoffel symbols and curvature tensors
- **Transparent documentation** of approximations vs. exact computation

### 2. Lambda Calculus-Inspired Operations
- Abstraction, application, and composition in fiber spaces
- Structure-preserving transformations
- **Clear distinction** from formal lambda calculus

### 3. Information-Geometric Optimization
- Diagonal Fisher information approximation
- Efficient natural gradient descent
- O(n) space complexity vs. O(nÂ²) for full Fisher matrix

### 4. Sheaf-Theoretic Consistency
- Probabilistic gluing conditions across semantic patches
- Jensen-Shannon divergence for soft constraints
- **Honest assessment** of approximation to formal sheaf theory

### 5. Comprehensive Experimental Design
- 13 systematic ablation studies
- 8 comparative baselines
- Rigorous statistical protocols (Wilson intervals, multiple testing corrections)

---

## ğŸ“– Documentation

### Core Documents

- **[ğŸ“„ Scientific Thesis v2.1 (Enhanced)](ManifoldGL_Scientific_Thesis_v2.1_ENHANCED.md)** - Main scientific contribution with peer review feedback incorporated
- **[ğŸ”¬ Peer Review Report](PEER_REVIEW_COMMITTEE_REPORT_COMPREHENSIVE.md)** - Multi-agent review (mathematical rigor, experimental validation, publication quality, critical analysis)
- **[ğŸ“Š Ablation Studies Framework](ablation_results/ABLATION_STUDIES.md)** - 13 systematic ablation studies
- **[ğŸ“ˆ Comparative Studies Framework](comparative_results/COMPARATIVE_STUDIES.md)** - 8 baseline comparisons
- **[ğŸ”§ Implementation Details](src/igbundle/README.md)** - Code documentation

### Research Reports

- **[ğŸ§ª AI Scientist Research Report](AI_SCIENTIST_RESEARCH_REPORT.md)** - Novel improvements and extensions (adaptive curvature, multi-scale attention, meta-learning)
- **[ğŸ“ Ablation Results](ablation_results.md)** - Riemannian vs. Euclidean preliminary study
- **[ğŸ—ºï¸ LLMOS Codemap](LLMOS_CODEMAP.md)** - Codebase architecture and navigation

### Version History

- **[v1.0](IGBundle_Thesis_v1.0.md)** - Initial concise scientific version
- **[Corrected Thesis](IGBundle_Corrected_Thesis.md)** - Mathematical corrections and foundations
- **[v2.0](ManifoldGL_Scientific_Thesis_v2.0.md)** - Comprehensive merge
- **[v2.1 Enhanced](ManifoldGL_Scientific_Thesis_v2.1_ENHANCED.md)** - Peer review feedback incorporated âœ¨ **CURRENT**

---

## ğŸ¤ Contributing

This is currently a research preview. For collaboration inquiries:

1. **Review the thesis**: [ManifoldGL_Scientific_Thesis_v2.1_ENHANCED.md](ManifoldGL_Scientific_Thesis_v2.1_ENHANCED.md)
2. **Check peer review**: [PEER_REVIEW_COMMITTEE_REPORT_COMPREHENSIVE.md](PEER_REVIEW_COMMITTEE_REPORT_COMPREHENSIVE.md)
3. **Open an issue** for discussions or suggestions

---

## ğŸ“œ License

**All Rights Reserved** - This is proprietary research code. Contact the author for licensing inquiries.

---

## ğŸ”— Citations

If you use this work, please cite:

```bibtex
@software{vilela2026manifoldgl,
  title={ManifoldGL: Information-Geometric Bundle Adapters for Large Language Models},
  author={Vilela Jato, JesÃºs},
  year={2026},
  url={https://github.com/jesusvilela/IGBundle-LLM},
  note={Research Preview v2.1}
}
```

### Key References

- Vaswani et al. (2017). *Attention is All You Need*. NeurIPS.
- Hu et al. (2021). *LoRA: Low-Rank Adaptation of Large Language Models*. ICLR.
- Nickel & Kiela (2017). *PoincarÃ© Embeddings for Learning Hierarchical Representations*. NeurIPS.
- Bronstein et al. (2021). *Geometric Deep Learning*. arXiv:2104.13478.
- Amari (1998). *Natural Gradient Works Efficiently in Learning*. Neural Computation.

---

## ğŸ“¬ Contact

**Author**: JesÃºs Vilela Jato
**Research**: Independent
**GitHub**: [@jesusvilela](https://github.com/jesusvilela)

---

<div align="center">

**ğŸŒŒ Exploring the Geometry of Meaning**

*"Not all who wander in non-Euclidean spaces are lost."*

[![GitHub stars](https://img.shields.io/github/stars/jesusvilela/IGBundle-LLM?style=social)](https://github.com/jesusvilela/IGBundle-LLM)
[![GitHub forks](https://img.shields.io/github/forks/jesusvilela/IGBundle-LLM?style=social)](https://github.com/jesusvilela/IGBundle-LLM/fork)

</div>
